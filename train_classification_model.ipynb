{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5801c1f",
   "metadata": {},
   "source": [
    "# Import required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cec642fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Lambda\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad34a4b",
   "metadata": {},
   "source": [
    "# Create a custom generator\n",
    "\n",
    "This makes sure, that the data is not loaded at once into the memory, when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afd492a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_filenames, labels, batch_size):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]        \n",
    "        return np.array([\n",
    "            (cv2.imread(str(file_name)))\n",
    "            for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7890b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7b97c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"test_data\")\n",
    "df = pd.read_csv(path/'artists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf774a",
   "metadata": {},
   "source": [
    "# Check the distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b661df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  paintings\n",
      "48           Vincent van Gogh        877\n",
      "10                Edgar Degas        702\n",
      "33              Pablo Picasso        439\n",
      "38      Pierre-Auguste Renoir        336\n",
      "0              Albrecht DÃ¼rer        328\n",
      "35               Paul Gauguin        311\n",
      "15             Francisco Goya        291\n",
      "42                  Rembrandt        262\n",
      "1               Alfred Sisley        259\n",
      "46                     Titian        255\n",
      "30               Marc Chagall        239\n",
      "43              Rene Magritte        194\n",
      "2           Amedeo Modigliani        193\n",
      "36                  Paul Klee        188\n",
      "21              Henri Matisse        186\n",
      "4                 Andy Warhol        181\n",
      "32             Mikhail Vrubel        171\n",
      "45          Sandro Botticelli        164\n",
      "29          Leonardo da Vinci        143\n",
      "37          Peter Paul Rubens        141\n",
      "44              Salvador Dali        139\n",
      "24           Hieronymus Bosch        137\n",
      "40             Pieter Bruegel        134\n",
      "9             Diego Velazquez        128\n",
      "28           Kazimir Malevich        126\n",
      "16                Frida Kahlo        120\n",
      "18          Giotto di Bondone        119\n",
      "19               Gustav Klimt        117\n",
      "41                    Raphael        109\n",
      "27                  Joan Miro        102\n",
      "3               Andrei Rublev         99\n",
      "5            Camille Pissarro         91\n",
      "11              Edouard Manet         90\n",
      "47         Vasiliy Kandinskiy         88\n",
      "13                   El Greco         87\n",
      "39              Piet Mondrian         84\n",
      "26               Jan van Eyck         81\n",
      "23  Henri de Toulouse-Lautrec         81\n",
      "7                Claude Monet         73\n",
      "8                Diego Rivera         70\n",
      "22             Henri Rousseau         70\n",
      "12               Edvard Munch         67\n",
      "49             William Turner         66\n",
      "20            Gustave Courbet         59\n",
      "6                  Caravaggio         55\n",
      "31               Michelangelo         49\n",
      "34               Paul Cezanne         47\n",
      "17             Georges Seurat         43\n",
      "14           Eugene Delacroix         31\n",
      "25            Jackson Pollock         24\n"
     ]
    }
   ],
   "source": [
    "artists_df = df[['name', 'paintings']].groupby(['name'], as_index = False).sum()\n",
    "names = artists_df.sort_values('paintings', ascending = False)[:50]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce816063",
   "metadata": {},
   "source": [
    "# Create a list with all paintings and artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdba9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = Path(path/'images/images')\n",
    "\n",
    "painting_list = []\n",
    "for path, subdirs, files in os.walk(images_dir):\n",
    "    for name in files:\n",
    "        img = os.path.join(path, name)\n",
    "        painting_list.extend([img])\n",
    "\n",
    "#only works on windows\n",
    "artist_list = []\n",
    "for painting in painting_list:\n",
    "    artist = painting.split('\\\\')[3]\n",
    "    artist_list.extend([artist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8f6a7",
   "metadata": {},
   "source": [
    "# Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa779043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  represents  Rembrandt\n",
      "1  represents  Rene_Magritte\n",
      "2  represents  Salvador_Dali\n",
      "3  represents  Sandro_Botticelli\n",
      "4  represents  Titian\n",
      "5  represents  Vasiliy_Kandinskiy\n",
      "6  represents  Vincent_van_Gogh\n",
      "7  represents  William_Turner\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array(artist_list)  \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(pd.Series(y))\n",
    "classes = list(encoder.classes_)\n",
    "for i in range(len(classes)):\n",
    "    print(i, ' represents ', classes[i])\n",
    "\n",
    "y = keras.utils.to_categorical(y, len(classes))\n",
    "print(y)\n",
    "\n",
    "X = np.array(painting_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68b642",
   "metadata": {},
   "source": [
    "# Split data into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58de262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf62842",
   "metadata": {},
   "source": [
    "# Prepare generators for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de43223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_batch_generator = CustomGenerator(X_train, y_train, batch_size)\n",
    "validation_batch_generator = CustomGenerator(X_val, y_val, batch_size)\n",
    "training_size = len(X_train)\n",
    "validation_size = len(X_val)\n",
    "test_size = len(X_test)\n",
    "input_shape = (cv2.imread(str(painting_list[0]))).shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427ae7e",
   "metadata": {},
   "source": [
    "# A model based on VGG-16's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7791e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vgg16_model(input_shape, num_classes):\n",
    "    # Generate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional\n",
    "    model.add(Conv2D(input_shape=input_shape, filters=64, kernel_size=(3, 3),\n",
    "                     padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 2: Convolutional\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 3: MaxPooling\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 4: Convolutional\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 5: Convolutional\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 6: MaxPooling\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 7: Convolutional\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 8: Convolutional\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 9: Convolutional\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 10: MaxPooling\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 11: Convolutional\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 12: Convolutional\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 13: Convolutional\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 14: MaxPooling\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 15: Convolutional\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 16: Convolutional\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 17: Convolutional\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # Layer 18: MaxPooling\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 19: Flatten\n",
    "    model.add(Flatten())\n",
    "    # Layer 20: Fully Connected Layer\n",
    "    model.add(Dense(units=4096, activation='relu'))\n",
    "    # Layer 21: Fully Connected Layer\n",
    "    model.add(Dense(units=4096, activation='relu'))\n",
    "    # Layer 22: Softmax Layer\n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e07c03",
   "metadata": {},
   "source": [
    "# A model based on an image classification tutorial by keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "552fca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keras_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    activation = \"softmax\"\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3e295",
   "metadata": {},
   "source": [
    "# Train keras-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "048658c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 224, 224, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 112, 112, 12  3584        ['rescaling_2[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 112, 112, 12  512        ['conv2d_8[0][0]']               \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 112, 112, 12  0           ['batch_normalization_16[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 112, 112, 12  0           ['activation_16[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d_14 (Separable  (None, 112, 112, 25  34176      ['activation_17[0][0]']          \n",
      " Conv2D)                        6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 112, 112, 25  1024       ['separable_conv2d_14[0][0]']    \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 112, 112, 25  0           ['batch_normalization_17[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d_15 (Separable  (None, 112, 112, 25  68096      ['activation_18[0][0]']          \n",
      " Conv2D)                        6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 112, 112, 25  1024       ['separable_conv2d_15[0][0]']    \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 56, 56, 256)  0          ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 56, 56, 256)  33024       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 56, 56, 256)  0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 56, 56, 256)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_16 (Separable  (None, 56, 56, 512)  133888     ['activation_19[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 56, 56, 512)  2048       ['separable_conv2d_16[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 56, 56, 512)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_17 (Separable  (None, 56, 56, 512)  267264     ['activation_20[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 56, 56, 512)  2048       ['separable_conv2d_17[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 28, 28, 512)  0          ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 28, 28, 512)  131584      ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 28, 28, 512)  0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 28, 28, 512)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_18 (Separable  (None, 28, 28, 728)  378072     ['activation_21[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 28, 28, 728)  2912       ['separable_conv2d_18[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 28, 28, 728)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_19 (Separable  (None, 28, 28, 728)  537264     ['activation_22[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 28, 28, 728)  2912       ['separable_conv2d_19[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 728)  0          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 14, 14, 728)  373464      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 14, 14, 728)  0           ['max_pooling2d_8[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_20 (Separable  (None, 14, 14, 1024  753048     ['add_8[0][0]']                  \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 14, 14, 1024  4096       ['separable_conv2d_20[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 14, 14, 1024  0           ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 1024)        0           ['activation_23[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8)            8200        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,738,240\n",
      "Trainable params: 2,729,952\n",
      "Non-trainable params: 8,288\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_keras = make_keras_model(input_shape, len(classes))\n",
    "print(model_keras.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dcb1c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justu\\AppData\\Local\\Temp\\ipykernel_20648\\1483329134.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_keras.fit_generator(generator=training_batch_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 269s 3s/step - loss: 1.5084 - accuracy: 0.4981 - val_loss: 1.9930 - val_accuracy: 0.0885\n",
      "Epoch 2/6\n",
      "102/102 [==============================] - 259s 3s/step - loss: 1.2868 - accuracy: 0.5543 - val_loss: 2.0793 - val_accuracy: 0.1719\n",
      "Epoch 3/6\n",
      "102/102 [==============================] - 259s 3s/step - loss: 1.1529 - accuracy: 0.6049 - val_loss: 2.3723 - val_accuracy: 0.1719\n",
      "Epoch 4/6\n",
      "102/102 [==============================] - 256s 3s/step - loss: 1.0761 - accuracy: 0.6210 - val_loss: 2.4821 - val_accuracy: 0.2031\n",
      "Epoch 5/6\n",
      "102/102 [==============================] - 265s 3s/step - loss: 1.0367 - accuracy: 0.6327 - val_loss: 1.6959 - val_accuracy: 0.3438\n",
      "Epoch 6/6\n",
      "102/102 [==============================] - 269s 3s/step - loss: 0.9405 - accuracy: 0.6698 - val_loss: 1.2292 - val_accuracy: 0.5729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222932e8af0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model_keras.fit_generator(generator=training_batch_generator,\n",
    "                    steps_per_epoch=int(training_size // batch_size),\n",
    "                    epochs=6,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_batch_generator,\n",
    "                    validation_steps=int(validation_size // batch_size)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01897aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.save(Path('model_keras_test.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f38238",
   "metadata": {},
   "source": [
    "# Train VGG16-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e088cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 112, 112, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 56, 56, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 28, 28, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 14, 14, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 7, 7, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 32776     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,293,320\n",
      "Trainable params: 134,293,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = make_vgg16_model(input_shape, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c638879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justu\\AppData\\Local\\Temp\\ipykernel_20648\\737468964.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_vgg16.fit_generator(generator=training_batch_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 504s 5s/step - loss: 48.5360 - accuracy: 0.3957 - val_loss: 1.7226 - val_accuracy: 0.4531\n",
      "Epoch 2/6\n",
      "102/102 [==============================] - 531s 5s/step - loss: 1.7534 - accuracy: 0.4333 - val_loss: 1.7199 - val_accuracy: 0.4531\n",
      "Epoch 3/6\n",
      "102/102 [==============================] - 499s 5s/step - loss: 1.7396 - accuracy: 0.4346 - val_loss: 1.7169 - val_accuracy: 0.4531\n",
      "Epoch 4/6\n",
      "102/102 [==============================] - 516s 5s/step - loss: 1.7367 - accuracy: 0.4352 - val_loss: 1.7286 - val_accuracy: 0.4531\n",
      "Epoch 5/6\n",
      "102/102 [==============================] - 520s 5s/step - loss: 1.7403 - accuracy: 0.4340 - val_loss: 1.7214 - val_accuracy: 0.4531\n",
      "Epoch 6/6\n",
      "102/102 [==============================] - 524s 5s/step - loss: 1.7401 - accuracy: 0.4340 - val_loss: 1.7254 - val_accuracy: 0.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222938925f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model_vgg16.fit_generator(generator=training_batch_generator,\n",
    "                    steps_per_epoch=int(training_size // batch_size),\n",
    "                    epochs=6,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_batch_generator,\n",
    "                    validation_steps=int(validation_size // batch_size)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.save(Path('model_vgg16_test.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
