{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  42\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import HTML\n",
    "import torchvision.utils as vutils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.animation as animation\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 42\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cant get this fucking thing to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training from scratch, set to True\n",
    "train = True\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 1\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
    "img_size = 256\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "n_channels = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "z_vector = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "f_map_g = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "f_map_d = 64\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lrG , lrD = 0.0002 , 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1, beta2 = 0.5, 0.999\n",
    "\n",
    "# Number of classes.\n",
    "n_class = 51\n",
    "\n",
    "# Root directory of dataset location\n",
    "root = 'C:/Users/tfiel/Documents/Python Scripts/CS595A/datasets'\n",
    "\n",
    "Lambda = 100 #lambda for L1 loss\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "if train == True:\n",
    "    # Define the data directory and the data transforms\n",
    "    data_dir = root + '/top_artists/images/'\n",
    "\n",
    "    # Load the dataset using ImageFolder\n",
    "    top_artists = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "    n_class = len(top_artists.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train == True:\n",
    "    train_set, test_set = train_test_split(top_artists, random_state=0, test_size=0.2)\n",
    "\n",
    "    # Create a data loader for the dataset\n",
    "    #Dtr = DataLoader(top_artists, batch_size=batch_size, shuffle=True)\n",
    "    Dtr = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    Dte = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sure that we have a directory of clean and adversarial images\n",
    "dir = root + '/test_data/images/adversarial_images'\n",
    "\n",
    "img_name = []\n",
    "for path, subdirs, files in os.walk(dir):\n",
    "    for name in files:\n",
    "        img_name.append(name)\n",
    "dir = root + '/test_data/images/clean_images'\n",
    "for path, subdirs, files in os.walk(dir):\n",
    "    for name in files:\n",
    "        if name not in img_name:\n",
    "            img_path = (path+'/'+name).replace(\"\\\\\", \"/\")\n",
    "            os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildConv(nn.Module):\n",
    "    def __init__(self , input_size , output_size , kernel_size = 4 , stride = 2 , padding = 1 , batch_norm = True, activation = True):\n",
    "        super(BuildConv , self).__init__()\n",
    "        self.Conv = nn.Conv2d(input_size,  output_size , kernel_size , stride , padding)\n",
    "        self.activation = activation\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2 , True)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.BatchNorm = nn.BatchNorm2d(output_size)\n",
    "    def forward(self , x):\n",
    "        if self.activation:\n",
    "            op = self.Conv(self.leaky_relu(x))\n",
    "        else:\n",
    "            op = self.Conv(x)\n",
    "        if self.batch_norm:\n",
    "            return self.BatchNorm(op)\n",
    "        else:\n",
    "            return op\n",
    "\n",
    "#BuildDeconv is a utility class to help build deconv layers\n",
    "class BuildDeconv(nn.Module):\n",
    "    def __init__(self , input_size , output_size , kernel_size = 4 , stride = 2 , padding = 1 , batch_norm = True , dropout = False):\n",
    "        super(BuildDeconv ,self).__init__()\n",
    "        self.DeConv = nn.ConvTranspose2d(input_size , output_size , kernel_size , stride , padding)\n",
    "        self.BatchNorm = nn.BatchNorm2d(output_size)\n",
    "        self.Dropout = nn.Dropout2d(0.5)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm = batch_norm\n",
    "    def forward(self , x):\n",
    "        if self.batch_norm:\n",
    "            op = self.BatchNorm(self.DeConv(self.relu(x)))\n",
    "        else:\n",
    "            op = self.DeConv(self.relu(x))\n",
    "        if self.dropout:\n",
    "            return self.Dropout(op)\n",
    "        else:\n",
    "            return op\n",
    "    \n",
    "#Let's define our Generator class (U-net architecture)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self ,input_dim , num_filters , output_dim):\n",
    "        super(Generator , self).__init__()\n",
    "        #Encoder\n",
    "        #self.conv1 \n",
    "        self.conv1 = BuildConv(input_dim , num_filters , batch_norm = True  , activation = False)\n",
    "        self.conv2 = BuildConv(num_filters , num_filters*2)\n",
    "        self.conv3 = BuildConv(num_filters*2 , num_filters*4)\n",
    "        self.conv4 = BuildConv(num_filters*4 , num_filters*8)\n",
    "        self.conv5 = BuildConv(num_filters*8 , num_filters*8)\n",
    "        self.conv6 = BuildConv(num_filters*8 , num_filters*8)\n",
    "        self.conv7 = BuildConv(num_filters*8 , num_filters*8)\n",
    "        self.conv8 = BuildConv(num_filters*8 , num_filters*8 , batch_norm= False)\n",
    "        #Decoder\n",
    "        self.deconv1 = BuildDeconv(num_filters*8 , num_filters*8 , dropout= True)\n",
    "        self.deconv2 = BuildDeconv(num_filters*8*2 , num_filters*8 , dropout= True)\n",
    "        self.deconv3 = BuildDeconv(num_filters*8*2 , num_filters*8 , dropout= True)\n",
    "        self.deconv4 = BuildDeconv(num_filters*8*2 , num_filters*8)\n",
    "        self.deconv5 = BuildDeconv(num_filters*8*2 , num_filters*4)\n",
    "        self.deconv6 = BuildDeconv(num_filters*4*2 , num_filters*2)\n",
    "        self.deconv7 = BuildDeconv(num_filters*2*2 , num_filters)\n",
    "        self.deconv8 = BuildDeconv(num_filters*2 , output_dim , batch_norm= False)\n",
    "    def forward(self , x):\n",
    "        #Encoder\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        enc4 = self.conv4(enc3)\n",
    "        enc5 = self.conv5(enc4)\n",
    "        enc6 = self.conv6(enc5)\n",
    "        enc7 = self.conv7(enc6)\n",
    "        enc8 = self.conv8(enc7)\n",
    "        #Decoder with skip connections\n",
    "        dec1 = self.deconv1(enc8)\n",
    "        dec1 = torch.cat([dec1, enc7], 1)\n",
    "        dec2 = self.deconv2(dec1)\n",
    "        dec2 = torch.cat([dec2, enc6], 1)\n",
    "        dec3 = self.deconv3(dec2)\n",
    "        dec3 = torch.cat([dec3, enc5], 1)\n",
    "        dec4 = self.deconv4(dec3)\n",
    "        dec4 = torch.cat([dec4, enc4], 1)\n",
    "        dec5 = self.deconv5(dec4)\n",
    "        dec5 = torch.cat([dec5, enc3], 1)\n",
    "        dec6 = self.deconv6(dec5)\n",
    "        dec6 = torch.cat([dec6, enc2], 1)\n",
    "        dec7 = self.deconv7(dec6)\n",
    "        dec7 = torch.cat([dec7, enc1], 1)\n",
    "        dec8 = self.deconv8(dec7)\n",
    "        out = torch.nn.Tanh()(dec8)\n",
    "        return out\n",
    "\n",
    "    def normal_weight_init(self , mean = 0.0 ,std = 0.02):\n",
    "        ''' This function initializes weights of layers'''\n",
    "        for m in self.children():\n",
    "            if isinstance(m , BuildConv):\n",
    "                nn.init.normal_(m.Conv.weight , mean , std)\n",
    "            if isinstance(m , BuildDeconv):\n",
    "                nn.init.normal_(m.DeConv.weight , mean , std)\n",
    "\n",
    "#Lets define class Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self , input_dim , num_filters , output_dim):\n",
    "        super(Discriminator , self).__init__()\n",
    "        self.conv1 = BuildConv(input_dim , num_filters , batch_norm= False , activation= False)\n",
    "        self.conv2 = BuildConv(num_filters , num_filters*2)\n",
    "        self.conv3 = BuildConv(num_filters*2 , num_filters*4)\n",
    "        self.conv4 = BuildConv(num_filters*4 , num_filters*8 , stride = 1)\n",
    "        self.conv5 = BuildConv(num_filters*8 , output_dim , stride = 1 , batch_norm= False)\n",
    "    def forward(self , x , label):\n",
    "        print('0: {}'.format(x.shape))\n",
    "        x = torch.cat([x , label] , 1)\n",
    "        print('1: {}'.format(x.shape))\n",
    "        x = self.conv1(x)\n",
    "        print('2: {}'.format(x.shape))\n",
    "        x = self.conv2(x)\n",
    "        print('3: {}'.format(x.shape))\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        op = torch.nn.Sigmoid()(x)\n",
    "        return op\n",
    "\n",
    "    def normal_weight_init(self , mean = 0.0 , std = 0.02):\n",
    "        ''' This function initializes the weights for layers'''\n",
    "        for m in self.children():\n",
    "            if isinstance(m , BuildConv):\n",
    "                nn.init.normal_(m.Conv.weight , mean , std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "data = iter(Dtr)\n",
    "img , p = data.next()\n",
    "print(img.shape , p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Losses\n",
    "def plot_loss(g_loss , d_loss ,num_epochs, save = False , save_dir = 'results/' , show = False):\n",
    "\n",
    "    fig , ax = plt.subplots()\n",
    "    ax.set_xlim(0 , num_epochs)\n",
    "    ax.set_ylim(0 , max(np.max(g_loss) , np.max(d_loss))*1.1)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(d_loss , label = 'Discriminator')\n",
    "    plt.plot(g_loss , label = 'Generator')\n",
    "    plt.legend()\n",
    "\n",
    "    if save:\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        save_fn  = save_dir + 'loss_values_epoch_{:d}'.format(num_epochs) + '.png'\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if save:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "#Function to plot test results\n",
    "\n",
    "def plot_test_result(input, target, gen_image, epoch, training=True, save=False, save_dir='results/', show=False, fig_size=(5, 5)):\n",
    "    if not training:\n",
    "        fig_size = (input.size(2) * 3 / 100, input.size(3)/100)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=fig_size)\n",
    "    imgs = [input, gen_image, target]\n",
    "    for ax, img in zip(axes.flatten(), imgs):\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "        # Scale to 0-255\n",
    "        img = (((img[0] - img[0].min()) * 255) / (img[0].max() - img[0].min())).numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "        ax.imshow(img, cmap=None, aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    if training:\n",
    "        title = 'Epoch {0}'.format(epoch + 1)\n",
    "        fig.text(0.5, 0.04, title, ha='center')\n",
    "\n",
    "    # save figure\n",
    "    if save:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        if training:\n",
    "            save_fn = save_dir + 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
    "        else:\n",
    "            save_fn = save_dir + 'Test_result_{:d}'.format(epoch+1) + '.png'\n",
    "            fig.subplots_adjust(bottom=0)\n",
    "            fig.subplots_adjust(top=1)\n",
    "            fig.subplots_adjust(right=1)\n",
    "            fig.subplots_adjust(left=0)\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(3 , f_map_g , 3)\n",
    "netD = Discriminator(4 , f_map_d , 1)\n",
    "netG.normal_weight_init(mean = 0.0 , std = 0.02)\n",
    "netD.normal_weight_init(mean = 0.0 , std  = 0.02)\n",
    "\n",
    "#Loss functions\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "l1_loss = torch.nn.L1Loss()\n",
    "\n",
    "#Defining the optimizers\n",
    "G_optim = torch.optim.Adam(netG.parameters() , lr = lrG , betas = (beta1 , beta2))\n",
    "D_optim = torch.optim.Adam(netD.parameters() , lr = lrD , betas = (beta1 , beta2))\n",
    "\n",
    "\n",
    "test_input, test_target = Dte.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Training############\n",
    "# Training Loop\n",
    "def batch_gd(netG, netD, Dtr, epochs):\n",
    "    # Lists to keep track of progress\n",
    "    print_every = 50\n",
    "    start = time.time()\n",
    "    G_avg_loss , D_avg_loss = [] , []\n",
    "\n",
    "    netD.to(device)\n",
    "    netG.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        g_loss , d_loss = [] , []\n",
    "        for i , (inp , target) in enumerate(Dtr):\n",
    "            x , y = Variable(inp.to(device)) , Variable(target.to(device))\n",
    "            # Expand the label tensor to match the spatial dimensions of the input\n",
    "            y = y.view(y.size(0), 1, 1, 1)\n",
    "            y = y.repeat(1, 1, x.size(2), x.size(3))\n",
    "            \n",
    "            #Training the discriminator with real_data\n",
    "            D_real = netD(x , y).squeeze()\n",
    "            real_target = Variable(torch.ones(D_real.size()).to(device))\n",
    "            D_real_loss = bce_loss(D_real , real_target)\n",
    "            \n",
    "            #Training the discriminator with fake images\n",
    "            gen_img = netG(x)\n",
    "            D_fake = netD(x , gen_img).squeeze()\n",
    "            fake_target = Variable(torch.ones(D_fake.size()).to(device))\n",
    "            \n",
    "            D_fake_loss = bce_loss(D_fake , fake_target)\n",
    "            \n",
    "            #Back Propogation\n",
    "            D_loss = (D_real_loss + D_fake_loss) * 0.5\n",
    "            D_optim.zero_grad()\n",
    "            D_loss.backward()\n",
    "            D_optim.step()\n",
    "            \n",
    "            #Training the Generator\n",
    "            gen_img = netG(x)\n",
    "            D_fake_decision = netD(x , gen_img).squeeze()\n",
    "            G_fake_loss = bce_loss(D_fake_decision , real_target)\n",
    "            \n",
    "            #L1 loss\n",
    "            \n",
    "            G_l1 = Lambda*l1_loss(gen_img, y)\n",
    "            \n",
    "            #total generator loss\n",
    "            \n",
    "            G_loss = G_l1 + G_fake_loss\n",
    "            G_optim.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optim.step()\n",
    "            \n",
    "            \n",
    "            g_loss.append(G_loss.item())\n",
    "            d_loss.append(D_loss.item())\n",
    "            if(i % print_every) == 0 :\n",
    "                print(\"Epoch[{}/{}]|| D_loss : {:.4f} || G_loss : {:.4f}\".format(epoch + 1 , epochs\n",
    "                                                                    , D_loss.item() , G_loss.item()))\n",
    "            \n",
    "        #avg_loss values\n",
    "        G_avg_loss.append(torch.mean(torch.FloatTensor(g_loss)))\n",
    "        D_avg_loss.append(torch.mean(torch.FloatTensor(d_loss)))\n",
    "        \n",
    "        #Showing result for test image\n",
    "        gen_image = netG(Variable(test_input.cuda()))\n",
    "        gen_image = gen_image.cpu().data\n",
    "        plot_test_result(test_input , test_target , gen_image , epoch ,save = True ,save_dir = './generated_samples/cgan/')\n",
    "    print(time.time() - start)\n",
    "    \n",
    "#Plot average losses\n",
    "#Utility.plot_loss(G_avg_loss , D_avg_loss , num_epochs , save = True , save_dir = save_dir)\n",
    "\n",
    "#make gif\n",
    "#Utility.generate_gif('maps' , num_epochs , save_dir = save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([1, 3, 256, 256])\n",
      "1: torch.Size([1, 4, 256, 256])\n",
      "2: torch.Size([1, 64, 128, 128])\n",
      "3: torch.Size([1, 128, 64, 64])\n",
      "0: torch.Size([1, 3, 256, 256])\n",
      "1: torch.Size([1, 6, 256, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 4, 4, 4], expected input[1, 6, 256, 256] to have 4 channels, but got 6 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\3178368362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mbatch_gd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Save the trained models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnetD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnetG\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trained_gan_{}.pkl'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\3912636646.py\u001b[0m in \u001b[0;36mbatch_gd\u001b[1;34m(netG, netD, Dtr, epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m#Training the discriminator with fake images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mgen_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mD_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mgen_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mfake_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_fake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\tfiel\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\1948316859.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, label)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\tfiel\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\1948316859.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\tfiel\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\tfiel\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\tfiel\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 4, 4, 4], expected input[1, 6, 256, 256] to have 4 channels, but got 6 channels instead"
     ]
    }
   ],
   "source": [
    "if train == True:\n",
    "    batch_gd(netG, netD, Dtr, epochs)\n",
    "    # Save the trained models\n",
    "    model_list = [netD,netG]\n",
    "    pickle.dump(model_list, open('trained_gan_{}.pkl'.format(img_size), 'wb'))\n",
    "\n",
    "else:\n",
    "    # Load already trained models\n",
    "    model_list = pickle.load(open('trained_gan_{}.pkl'.format(img_size), 'rb'))\n",
    "    netD = model_list[0]\n",
    "    netG = model_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28608\\1084985507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_avg_loss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generator Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(range(1 , epochs + 1),G_avg_loss , color = 'blue')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Generator Loss\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1 , num_epochs + 1),D_avg_loss , color = 'blue')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Discriminator Loss\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "for i ,(inp , target) in enumerate(Dte):\n",
    "    \n",
    "    x , y = Variable(inp.cuda()) , Variable(target.cuda())\n",
    "    gen_image = Gen(x)\n",
    "    gen_image = gen_image.cpu()\n",
    "    \n",
    "    Utility.plot_test_result(inp , target, gen_image , i ,training = False , save = True , save_dir = save_test_dir)\n",
    "    print('%d images are generated.' % (i + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
